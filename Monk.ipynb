{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Monk**"
      ],
      "metadata": {
        "id": "hmPj-B5drUCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install tensorflow_decision_forests\n",
        "!pip install wurlitzer\n",
        "!pip install scikeras[tensorflow]"
      ],
      "metadata": {
        "id": "Ynlp1gjJriPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "# MLP\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "# SVM\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Decision Forest\n",
        "import tensorflow_decision_forests as tfdf\n",
        "\n",
        "# Cross-validation\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import KFold, StratifiedKFold, cross_val_score, train_test_split\n",
        "from sklearn.metrics import make_scorer, accuracy_score, log_loss\n",
        "\n",
        "# Import statistics\n",
        "from statistics import mean, stdev, median"
      ],
      "metadata": {
        "id": "VTffeKXmrtgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQWKNE7xrCxf"
      },
      "outputs": [],
      "source": [
        "# Mount google drive to access data loaded on Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition of functions**"
      ],
      "metadata": {
        "id": "ve6wXsaLy2yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Definition of loss/accuracy plot functions\n",
        "def loss_plot(history):\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "  epochs = range(1, len(loss) + 1)\n",
        "  plt.figure(figsize=(9, 5))\n",
        "  # Training and test loss\n",
        "  plt.plot(epochs, loss, label='Training loss', color='royalblue')\n",
        "  plt.plot(epochs, val_loss, label='Test loss', linestyle='dashed', color='darkorange')\n",
        "  plt.title('Training & Test Loss', fontsize=14)\n",
        "  plt.xlabel('Epochs', fontsize=14)\n",
        "  plt.ylabel('Loss', fontsize=14)\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.legend(fontsize=14)\n",
        "  plt.show()\n",
        "\n",
        "def accuracy_plot(history):\n",
        "  acc = history.history['accuracy']\n",
        "  val_acc = history.history['val_accuracy']\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "  plt.figure(figsize=(9, 5))\n",
        "  # Training and test accuracy\n",
        "  plt.plot(epochs, acc, label='Training acc', color='royalblue')\n",
        "  plt.plot(epochs, val_acc, label='Test acc', linestyle='dashed', color='darkorange')\n",
        "  plt.title('Training & Test Accuracy', fontsize=14)\n",
        "  plt.xlabel('Epochs', fontsize=14)\n",
        "  plt.ylabel('Accuracy', fontsize=14)\n",
        "  plt.xticks(fontsize=12)\n",
        "  plt.yticks(fontsize=12)\n",
        "  plt.legend(fontsize=14)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "_0MUIZ9jrrOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Definition of MLP functions\n",
        "\n",
        "# Building and compiling model\n",
        "def build_model(activation, kernel_initializer, optimizer, units=2):\n",
        "  # Define the Model\n",
        "  model = keras.Sequential()\n",
        "  model.add(tf.keras.Input(shape=(17,)))\n",
        "  model.add(layers.Dense(units=units, activation=activation, kernel_initializer=kernel_initializer))\n",
        "  model.add(layers.Dense(units=units, activation=activation, kernel_initializer=kernel_initializer))\n",
        "  model.add(layers.Dense(units=1, activation='sigmoid'))\n",
        "  # Compile the model\n",
        "  model.compile(optimizer=optimizer,\n",
        "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "                metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "# Training model\n",
        "def train_model(model, X_train, y_train, X_test, y_test, batch_size=32, epochs=500, callbacks=None):\n",
        "  # Fit the model\n",
        "  history = model.fit(X_train,\n",
        "                      y_train,\n",
        "                      validation_data=(X_test, y_test),\n",
        "                      batch_size=batch_size,\n",
        "                      shuffle=True,\n",
        "                      epochs=epochs,\n",
        "                      callbacks=callbacks)\n",
        "  return history"
      ],
      "metadata": {
        "id": "bh--hcGUy0NK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Definition of Random Forest\n",
        "\n",
        "# Building model\n",
        "def create_rf_model(num_trees, max_depth, min_examples, algorithm='RANDOM', num_candidate_attributes=0, verbose=2):\n",
        "    # Define the model\n",
        "    rf_model = tfdf.keras.RandomForestModel(\n",
        "        num_trees=num_trees,\n",
        "        max_depth=max_depth,\n",
        "        min_examples=min_examples,\n",
        "        categorical_algorithm=algorithm,\n",
        "        num_candidate_attributes=num_candidate_attributes,\n",
        "        task=tfdf.keras.Task.CLASSIFICATION,\n",
        "        verbose=verbose)\n",
        "    return rf_model"
      ],
      "metadata": {
        "id": "jKpBQgu-2QKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Definition of Support Vector Machine\n",
        "def create_svm_model(kernel, C=1, degree=1, gamma='scale', verbose=2):\n",
        "  # Define the model\n",
        "  svm_model = SVC(kernel=kernel,\n",
        "                  C=C,\n",
        "                  degree=degree,\n",
        "                  gamma=gamma,\n",
        "                  verbose=verbose)\n",
        "  return svm_model\n"
      ],
      "metadata": {
        "id": "sv3mOGe94-GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**Monk 1**"
      ],
      "metadata": {
        "id": "_dkEIm-Ds0nY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Data preparation**"
      ],
      "metadata": {
        "id": "kURFFDPDtNYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training set**"
      ],
      "metadata": {
        "id": "EsxC_ZPJtcdT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the training dataset MONK-1\n",
        "path = '/content/drive/MyDrive/data/monk+s+problems/monks-1.train'\n",
        "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
        "\n",
        "monk_1_train = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
        "monk_1_train.set_index('ID', inplace=True)\n",
        "monk_1_train.shape"
      ],
      "metadata": {
        "id": "CQq5rHKHtYZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 5 rows\n",
        "monk_1_train.head()"
      ],
      "metadata": {
        "id": "Q-MEmhAPuEY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unique values for each column\n",
        "monk_1_train.nunique()"
      ],
      "metadata": {
        "id": "zgummz1KuEWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of records for the two classes\n",
        "monk_1_train['class'].value_counts()"
      ],
      "metadata": {
        "id": "wtnVIsBcuG_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding training set\n",
        "X_train_encoded = pd.get_dummies(monk_1_train, columns=col_names[1:-1])\n",
        "X_train_encoded.shape"
      ],
      "metadata": {
        "id": "TdEKCARutjyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded.head()"
      ],
      "metadata": {
        "id": "jRZAIHlquLAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train, X_train split\n",
        "y_train_monk1, X_train_monk1 = X_train_encoded['class'], X_train_encoded.iloc[:, 1:]\n",
        "\n",
        "print(f'y shape: {y_train_monk1.shape}')\n",
        "print(f'X shape: {X_train_monk1.shape}')"
      ],
      "metadata": {
        "id": "ocGBEDfstjtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test set**"
      ],
      "metadata": {
        "id": "jmdsQEbztuW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test dataset MONK-1\n",
        "path = '/content/drive/MyDrive/data/monk+s+problems/monks-1.test'\n",
        "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
        "\n",
        "monk_1_test = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
        "monk_1_test.set_index('ID', inplace=True)\n",
        "monk_1_test.shape"
      ],
      "metadata": {
        "id": "jDtX3wdottoE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding categorical variable\n",
        "monk_1_test_encoded = pd.get_dummies(monk_1_test, columns=col_names[1:-1])\n",
        "monk_1_test_encoded.shape"
      ],
      "metadata": {
        "id": "CdKUUvJkttlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test, X_test\n",
        "y_test_monk1, X_test_monk1 = monk_1_test_encoded['class'], monk_1_test_encoded.iloc[:, 1:]\n",
        "\n",
        "print(f'y shape: {y_test_monk1.shape}')\n",
        "print(f'X shape: {X_test_monk1.shape}')"
      ],
      "metadata": {
        "id": "Q_02DR0fttiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Multi Layer Perceptron - MLP**"
      ],
      "metadata": {
        "id": "fEEtt94cuOEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "mlp1 = build_model(activation='elu',\n",
        "                   kernel_initializer='HeUniform',\n",
        "                   units=2,\n",
        "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.04))\n",
        "\n",
        "# Fit model\n",
        "mlp1_history = train_model(mlp1, X_train_monk1, y_train_monk1, X_test_monk1, y_test_monk1, batch_size=32, epochs=500)"
      ],
      "metadata": {
        "id": "1xIhltauttfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss plot\n",
        "loss_plot(mlp1_history)"
      ],
      "metadata": {
        "id": "rnLGgMFyttcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy plot\n",
        "accuracy_plot(mlp1_history)"
      ],
      "metadata": {
        "id": "kt7__oKGtjqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on the training & test set\n",
        "results_TR = mlp1.evaluate(x=X_train_monk1, y=y_train_monk1)\n",
        "print(f\"train loss: {results_TR[0]}, train acc: {results_TR[1]}\")\n",
        "\n",
        "results_TS = mlp1.evaluate(x=X_test_monk1, y=y_test_monk1)\n",
        "print(f\"test loss: {results_TS[0]}, test acc: {results_TS[1]}\")"
      ],
      "metadata": {
        "id": "RslDlm3j02Ez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train the model multiple times to assess weights initialization influence\n",
        "\n",
        "trials = 5\n",
        "\n",
        "history_list = []\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "for trial in range(trials):\n",
        "    model = build_model(activation='elu',\n",
        "                        kernel_initializer='HeUniform',\n",
        "                        units=2,\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
        "    history = train_model(model, X_train_monk1, y_train_monk1, X_test_monk1, y_test_monk1, batch_size=32, epochs=500)\n",
        "    history_list.append(history)\n",
        "    results_train = model.evaluate(x=X_train_monk1, y=y_train_monk1)\n",
        "    results_test = model.evaluate(x=X_test_monk1, y=y_test_monk1)\n",
        "    # train\n",
        "    train_losses.append(results_train[0])\n",
        "    train_accuracies.append(results_train[1])\n",
        "    # test\n",
        "    test_losses.append(results_test[0])\n",
        "    test_accuracies.append(results_test[1])"
      ],
      "metadata": {
        "id": "M5EnAEA602B6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MLP 1 MODEL')\n",
        "print()\n",
        "print('TRAIN ACCURACY')\n",
        "print(f'train max: {np.amax(train_accuracies)}')\n",
        "print(f'train mean: {np.mean(train_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'train variance: {np.var(train_accuracies)}')\n",
        "print()\n",
        "print('TEST ACCURACY')\n",
        "print(f'test max: {np.amax(test_accuracies)}')\n",
        "print(f'test mean: {np.mean(test_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'test variance: {np.var(test_accuracies)}')"
      ],
      "metadata": {
        "id": "d1wq5LSq1ZX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Random Forest**"
      ],
      "metadata": {
        "id": "78Zj1F2p1x38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to categorical variables otherwise used by the RF as numerical\n",
        "monk_1_train_new = monk_1_train.astype(str)\n",
        "monk_1_test_new = monk_1_test.astype(str)\n",
        "\n",
        "print(monk_1_train_new.dtypes)\n",
        "print(monk_1_test_new.dtypes)"
      ],
      "metadata": {
        "id": "-rJogB0114Hv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "rf1 = create_rf_model(num_trees=300,\n",
        "                      max_depth=10,\n",
        "                      min_examples=1,\n",
        "                      algorithm='RANDOM',\n",
        "                      num_candidate_attributes=0)\n",
        "\n",
        "# Model assessment on training/test set\n",
        "rf1.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "rf1.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(monk_1_train_new, label='class'))"
      ],
      "metadata": {
        "id": "s0XNA2Fd1-gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the model\n",
        "rf1.summary()"
      ],
      "metadata": {
        "id": "7UlSL1nW4LDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loss & accuracy\n",
        "print('TRAINING:\\n')\n",
        "evaluation_TR = rf1.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_1_train_new, label='class'), return_dict=True)\n",
        "\n",
        "for name, value in evaluation_TR.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "4vHSPV0x4K36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loss & accuracy\n",
        "print('TEST:\\n')\n",
        "evaluation_TS = rf1.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_1_test_new, label='class'), return_dict=True)\n",
        "\n",
        "for name, value in evaluation_TS.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "-8DMiWb54kad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Support Vector Machine - SVM**"
      ],
      "metadata": {
        "id": "Vn8xdzB941r2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "svm1 = create_svm_model(kernel='poly',\n",
        "                        C=3,\n",
        "                        degree=2,\n",
        "                        gamma='scale')\n",
        "# Train the model\n",
        "svm1.fit(X_train_monk1, y_train_monk1)"
      ],
      "metadata": {
        "id": "HIXgD_-j46v_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model assessment on training & test set\n",
        "y_pred_TR = svm1.predict(X_train_monk1)\n",
        "Accuracy_TR = accuracy_score(y_train_monk1, y_pred_TR)\n",
        "\n",
        "y_pred_TS = svm1.predict(X_test_monk1)\n",
        "Accuracy_TS = accuracy_score(y_test_monk1, y_pred_TS)\n",
        "\n",
        "print(f'Train Accuracy: {Accuracy_TR}')\n",
        "print(f'Test Accuracy: {Accuracy_TS}')"
      ],
      "metadata": {
        "id": "m3kdOM2z5YMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**Monk 2**"
      ],
      "metadata": {
        "id": "vz9sQVzvs0dc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Data preparation**"
      ],
      "metadata": {
        "id": "xJHpVJqv6LV0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training set**"
      ],
      "metadata": {
        "id": "gklZfUyk6MDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the training dataset MONK-2\n",
        "path = '/content/drive/MyDrive/data/monk+s+problems/monks-2.train'\n",
        "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
        "\n",
        "monk_2_train = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
        "monk_2_train.set_index('ID', inplace=True)\n",
        "monk_2_train.shape"
      ],
      "metadata": {
        "id": "d043AmGV6ONB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 5 rows\n",
        "monk_2_train.head()"
      ],
      "metadata": {
        "id": "OY13ivWh6OED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unique values for each column\n",
        "monk_2_train.nunique()"
      ],
      "metadata": {
        "id": "-rewWuMU6N83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of records for the two classes\n",
        "monk_2_train['class'].value_counts()"
      ],
      "metadata": {
        "id": "-OkjxXTc6Wiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding training set\n",
        "X_train_encoded = pd.get_dummies(monk_2_train, columns=col_names[1:-1])\n",
        "X_train_encoded.shape"
      ],
      "metadata": {
        "id": "A3CY7iE56Wf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_encoded.head()"
      ],
      "metadata": {
        "id": "5wU0JalV6Wcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train, X_train split\n",
        "y_train_monk2, X_train_monk2 = X_train_encoded['class'], X_train_encoded.iloc[:, 1:]\n",
        "\n",
        "print(f'y shape: {y_train_monk2.shape}')\n",
        "print(f'X shape: {X_train_monk2.shape}')"
      ],
      "metadata": {
        "id": "1Kv4r2XN6bAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test set**"
      ],
      "metadata": {
        "id": "OjckSQQy6b_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test dataset MONK-2\n",
        "path = '/content/drive/MyDrive/data/monk+s+problems/monks-2.test'\n",
        "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
        "\n",
        "monk_2_test = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
        "monk_2_test.set_index('ID', inplace=True)\n",
        "monk_2_test.shape"
      ],
      "metadata": {
        "id": "q4HcdSyC6dYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding test set\n",
        "X_test_encoded = pd.get_dummies(monk_2_test, columns=col_names[1:-1])\n",
        "X_test_encoded.shape"
      ],
      "metadata": {
        "id": "eqACO-1X6d5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_encoded.head()"
      ],
      "metadata": {
        "id": "Ndi-DHBj6d2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test, X_test split\n",
        "y_test_monk2, X_test_monk2 = X_test_encoded['class'], X_test_encoded.iloc[:, 1:]\n",
        "\n",
        "print(f'y shape: {y_test_monk2.shape}')\n",
        "print(f'X shape: {X_test_monk2.shape}')"
      ],
      "metadata": {
        "id": "bmqajX616h-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Multi Layer Perceptron - MLP**"
      ],
      "metadata": {
        "id": "fLiP8yUz6jNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "mlp2 = build_model(activation='elu',\n",
        "                   kernel_initializer='RandomUniform',\n",
        "                   units=2,\n",
        "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
        "\n",
        "# Fit model\n",
        "mlp2_history = train_model(mlp2, X_train_monk2, y_train_monk2, X_test_monk2, y_test_monk2, batch_size=32, epochs=500)"
      ],
      "metadata": {
        "id": "Xmhy2zQ86rfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss plot\n",
        "loss_plot(mlp2_history)"
      ],
      "metadata": {
        "id": "psqoQHhu6sM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy plot\n",
        "accuracy_plot(mlp2_history)"
      ],
      "metadata": {
        "id": "eUeMNUUN6uJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on the training & test set\n",
        "results_TR = mlp2.evaluate(x=X_train_monk2, y=y_train_monk2)\n",
        "print(f\"train loss: {results_TR[0]}, train acc: {results_TR[1]}\")\n",
        "\n",
        "results_TS = mlp2.evaluate(x=X_test_monk2, y=y_test_monk2)\n",
        "print(f\"test loss: {results_TS[0]}, test acc: {results_TS[1]}\")"
      ],
      "metadata": {
        "id": "JDp-Ur4_68WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train the model multiple times to assess weights initialization influence\n",
        "\n",
        "trials = 5\n",
        "\n",
        "history_list = []\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "for trial in range(trials):\n",
        "    model = build_model(activation='elu',\n",
        "                        kernel_initializer='RandomUniform',\n",
        "                        units=2,\n",
        "                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.05))\n",
        "    history = train_model(model, X_train_monk2, y_train_monk2, X_test_monk2, y_test_monk2, batch_size=32, epochs=500)\n",
        "    history_list.append(history)\n",
        "    results_train = model.evaluate(x=X_train_monk2, y=y_train_monk2)\n",
        "    results_test = model.evaluate(x=X_test_monk2, y= y_test_monk2)\n",
        "    # train\n",
        "    train_losses.append(results_train[0])\n",
        "    train_accuracies.append(results_train[1])\n",
        "    # test\n",
        "    test_losses.append(results_test[0])\n",
        "    test_accuracies.append(results_test[1])"
      ],
      "metadata": {
        "id": "ouYxhTJd68S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MLP 2 MODEL')\n",
        "print()\n",
        "print('TRAIN ACCURACY')\n",
        "print(f'train max: {np.amax(train_accuracies)}')\n",
        "print(f'train mean: {np.mean(train_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'train variance: {np.var(train_accuracies)}')\n",
        "print()\n",
        "print('TEST ACCURACY')\n",
        "print(f'test max: {np.amax(test_accuracies)}')\n",
        "print(f'test mean: {np.mean(test_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'test variance: {np.var(test_accuracies)}')"
      ],
      "metadata": {
        "id": "bxr-Xvrv7gcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Random Forest**"
      ],
      "metadata": {
        "id": "Jqn9bRGD6tx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to categorical variables otherwise used by the RF as numerical\n",
        "monk_2_train_new = monk_2_train.astype(str)\n",
        "monk_2_test_new = monk_2_test.astype(str)\n",
        "\n",
        "print(monk_2_train_new.dtypes)\n",
        "print(monk_2_test_new.dtypes)"
      ],
      "metadata": {
        "id": "cXlOugs36xQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "rf2 = create_rf_model(num_trees=200,\n",
        "                      max_depth=15,\n",
        "                      min_examples=1,\n",
        "                      algorithm='RANDOM',\n",
        "                      num_candidate_attributes=0)\n",
        "\n",
        "# Model assessment on training/test set\n",
        "rf2.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "rf2.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(monk_2_train_new, label='class'))"
      ],
      "metadata": {
        "id": "9AoKmZlI8c8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the model\n",
        "rf2.summary()"
      ],
      "metadata": {
        "id": "Hlb8gmy-8c5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loss & accuracy\n",
        "print('TRAINING:\\n')\n",
        "evaluation_TR = rf2.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_2_train_new, label='class'), return_dict=True)\n",
        "\n",
        "for name, value in evaluation_TR.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "lmQ4uYgZ8pbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loss & accuracy\n",
        "print('TEST:\\n')\n",
        "evaluation_TS = rf2.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_2_test_new, label='class'), return_dict=True)\n",
        "\n",
        "for name, value in evaluation_TS.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "wy0PW40Q8pYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Support Vector Machine**"
      ],
      "metadata": {
        "id": "hVTErATw6xrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "svm2 = create_svm_model(kernel='poly',\n",
        "                        C=15,\n",
        "                        degree=2,\n",
        "                        gamma='scale')\n",
        "# Train the model\n",
        "svm2.fit(X_train_monk2, y_train_monk2)"
      ],
      "metadata": {
        "id": "1pd4e4F28-S3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model assessment on training & test set\n",
        "y_pred_TR = svm2.predict(X_train_monk2)\n",
        "Accuracy_TR = accuracy_score(y_train_monk2,y_pred_TR)\n",
        "\n",
        "y_pred_TS = svm2.predict(X_test_monk2)\n",
        "Accuracy_TS = accuracy_score(y_test_monk2, y_pred_TS)\n",
        "\n",
        "print(f'Train Accuracy: {Accuracy_TR}')\n",
        "print(f'Test Accuracy: {Accuracy_TS}')"
      ],
      "metadata": {
        "id": "CJAgwLxf89-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "##**Monk 3**"
      ],
      "metadata": {
        "id": "tCso8lEEs0TU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Data preparation**"
      ],
      "metadata": {
        "id": "Y2TkZ48N_Se5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training set**"
      ],
      "metadata": {
        "id": "fvZCaB_W_Tvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the training dataset MONK-3\n",
        "path = '/content/drive/MyDrive/data/monk+s+problems/monks-3.train'\n",
        "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
        "\n",
        "monk_3_train = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
        "monk_3_train.set_index('ID', inplace=True)\n",
        "monk_3_train.shape"
      ],
      "metadata": {
        "id": "3VRpHC-r_YKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the first 5 rows\n",
        "monk_3_train.head()"
      ],
      "metadata": {
        "id": "L7bL_JQT_ayL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count unique values for each column\n",
        "monk_3_train.nunique()"
      ],
      "metadata": {
        "id": "lViZb5rM_auo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count the number of records for the two classes\n",
        "monk_3_train['class'].value_counts()"
      ],
      "metadata": {
        "id": "lneFiNtg_arB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding training set\n",
        "X_design_encoded = pd.get_dummies(monk_3_train, columns=col_names[1:-1])\n",
        "X_design_encoded.shape"
      ],
      "metadata": {
        "id": "sp85GZSS_anX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_design_encoded.head()"
      ],
      "metadata": {
        "id": "9V8yvqhS_fw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train, X_train split\n",
        "y_design_monk3, X_design_monk3 = X_design_encoded['class'], X_design_encoded.iloc[:, 1:]\n",
        "\n",
        "print(f'y shape: {y_design_monk3.shape}')\n",
        "print(f'X shape: {X_design_monk3.shape}')"
      ],
      "metadata": {
        "id": "6XuQBvk-_fqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test set**"
      ],
      "metadata": {
        "id": "qpPZuHDT_WJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the test dataset MONK-3\n",
        "path = '/content/drive/MyDrive/data/monk+s+problems/monks-3.test'\n",
        "col_names = ['class', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'ID']\n",
        "\n",
        "monk_3_test = pd.read_csv(path, delimiter=' ', header=0, names=col_names)\n",
        "monk_3_test.set_index('ID', inplace=True)\n",
        "monk_3_test.shape"
      ],
      "metadata": {
        "id": "oaRcoKPA_Xuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding test set\n",
        "X_test_encoded = pd.get_dummies(monk_3_test, columns=col_names[1:-1])\n",
        "X_test_encoded.shape"
      ],
      "metadata": {
        "id": "ciHsz6hf_mRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_encoded.head()"
      ],
      "metadata": {
        "id": "V5ldI84y_mN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test, X_test split\n",
        "y_test_monk3, X_test_monk3 = X_test_encoded['class'], X_test_encoded.iloc[:, 1:]\n",
        "\n",
        "print(f'y shape: {y_test_monk3.shape}')\n",
        "print(f'X shape: {X_test_monk3.shape}')"
      ],
      "metadata": {
        "id": "mEj4zxMH_qho"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Multi Layer Perceptron - MLP**"
      ],
      "metadata": {
        "id": "gm73C4pl_v7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "mlp3 = build_model(activation='elu',\n",
        "                   kernel_initializer='HeUniform',\n",
        "                   units=2,\n",
        "                   optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.01))\n",
        "\n",
        "# Fit model\n",
        "mlp3_history = train_model(mlp3, X_design_monk3, y_design_monk3, X_test_monk3, y_test_monk3, batch_size=32, epochs=500)"
      ],
      "metadata": {
        "id": "xa78mLHg_qdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss plot\n",
        "loss_plot(mlp3_history)"
      ],
      "metadata": {
        "id": "zP8DwmVpAHcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy plot\n",
        "accuracy_plot(mlp3_history)"
      ],
      "metadata": {
        "id": "9HDnCzHlAHY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model evaluation on the training & test set\n",
        "results_TR = mlp3.evaluate(x=X_design_monk3, y=y_design_monk3)\n",
        "print(f\"train loss: {results_TR[0]}, train acc: {results_TR[1]}\")\n",
        "\n",
        "results_TS = mlp3.evaluate(x=X_test_monk3, y=y_test_monk3)\n",
        "print(f\"test loss: {results_TS[0]}, test acc: {results_TS[1]}\")"
      ],
      "metadata": {
        "id": "hAFssxOLAHVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# Train the model multiple times to assess weights initialization influence\n",
        "\n",
        "trials = 5\n",
        "\n",
        "history_list = []\n",
        "train_losses = []\n",
        "test_losses = []\n",
        "train_accuracies = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "for trial in range(trials):\n",
        "    model = build_model(activation='elu',\n",
        "                        kernel_initializer='HeUniform',\n",
        "                        units=2,\n",
        "                        optimizer=tf.keras.optimizers.SGD(learning_rate=0.05, momentum=0.01))\n",
        "    history = train_model(model, X_design_monk3, y_design_monk3, X_test_monk3, y_test_monk3, batch_size=64, epochs=500)\n",
        "    results_train = model.evaluate(x=X_design_monk3, y=y_design_monk3)\n",
        "    results_test = model.evaluate(x=X_test_monk3, y=y_test_monk3)\n",
        "    history_list.append(history)\n",
        "    # train\n",
        "    train_losses.append(results_train[0])\n",
        "    train_accuracies.append(results_train[1])\n",
        "    # test\n",
        "    test_losses.append(results_test[0])\n",
        "    test_accuracies.append(results_test[1])"
      ],
      "metadata": {
        "id": "rLi8CBLvAHRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MLP 3 MODEL')\n",
        "print()\n",
        "print('TRAIN ACCURACY')\n",
        "print(f'train max: {np.amax(train_accuracies)}')\n",
        "print(f'train mean: {np.mean(train_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'train variance: {np.var(train_accuracies)}')\n",
        "print()\n",
        "print('TEST ACCURACY')\n",
        "print(f'test max: {np.amax(test_accuracies)}')\n",
        "print(f'test mean: {np.mean(test_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'test variance: {np.var(test_accuracies)}')"
      ],
      "metadata": {
        "id": "_Mp11_zUAHN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Multi Layer Perceptron - MLP (Regularization & Early stopping)**"
      ],
      "metadata": {
        "id": "hrekRJjcBmtu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define early stopping\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "metadata": {
        "id": "DrafctZEDZRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy on individual fold\n",
        "accuracy_per_fold = []\n",
        "\n",
        "# Number of epochs\n",
        "epochs_per_fold = []\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# Run a K-folds cross-validation\n",
        "for  fold_idx, (train_indices, val_indices) in enumerate(kfold.split(X_design_monk3, y_design_monk3)):\n",
        "  print(f\"Running fold {fold_idx+1}\")\n",
        "\n",
        "  # Extract the training and validation examples\n",
        "  X_train_fold , y_train_fold = X_design_monk3.iloc[train_indices, :], y_design_monk3.iloc[train_indices]\n",
        "  X_val_fold , y_val_fold = X_design_monk3.iloc[val_indices, :], y_design_monk3.iloc[val_indices]\n",
        "\n",
        "  # Build model\n",
        "  model=build_model(units=2,\n",
        "                    activation='elu',\n",
        "                    kernel_initializer='HeUniform',\n",
        "                    optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.7, weight_decay=0.01))\n",
        "\n",
        "  # Train the model\n",
        "  history = model.fit(X_train_fold,\n",
        "                      y_train_fold,\n",
        "                      validation_data=(X_val_fold, y_val_fold),\n",
        "                      batch_size=64,\n",
        "                      epochs=1000,\n",
        "                      callbacks=[early_stopping],\n",
        "                      verbose=0)\n",
        "\n",
        "  # Evaluate the model\n",
        "  accuracy = model.evaluate(x=X_val_fold, y=y_val_fold)[1]\n",
        "  n_epochs = len(history.history['val_accuracy'])\n",
        "  print(f'val_accuracy: {accuracy}')\n",
        "  print(f'n_epochs: {n_epochs}')\n",
        "  accuracy_per_fold.append(accuracy)\n",
        "  epochs_per_fold.append(n_epochs)"
      ],
      "metadata": {
        "id": "Z1RWbBmQDZM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing results\n",
        "print(f\"Mean Accuracy: {mean(accuracy_per_fold)}\")\n",
        "print(f\"Stdev Accuracy: {stdev(accuracy_per_fold)}\")\n",
        "print(f'Median epochs: {median(sorted(epochs_per_fold))}')"
      ],
      "metadata": {
        "id": "XwDo5E6HDZIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_reg = build_model(activation='elu',\n",
        "                     kernel_initializer='HeUniform',\n",
        "                     units=2,\n",
        "                     optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.7, weight_decay=0.01)\n",
        "                     )\n",
        "\n",
        "history_reg = train_model(model_reg,\n",
        "                          X_design_monk3,\n",
        "                          y_design_monk3,\n",
        "                          X_test_monk3,\n",
        "                          y_test_monk3,\n",
        "                          batch_size=32,\n",
        "                          epochs=500)"
      ],
      "metadata": {
        "id": "Bd72bMcVmU65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_plot(history_reg)"
      ],
      "metadata": {
        "id": "yvI-cubYmVEh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_plot(history_reg)"
      ],
      "metadata": {
        "id": "ODi5GRQCmVMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Split design into train and validation sets\n",
        "train, val = train_test_split(X_design_encoded, test_size=0.30, shuffle=True, random_state=42)\n",
        "print(f'train shape: {train.shape}')\n",
        "print(f'val shape: {val.shape}')\n",
        "\n",
        "# y_test, X_test split\n",
        "y_train, X_train = train['class'], train.iloc[:, 1:]\n",
        "y_val, X_val = val['class'], val.iloc[:, 1:]\n",
        "print(f'X_train shape: {X_train.shape}, y_train shape: {y_train.shape}')\n",
        "print(f'X_val shape: {X_val.shape}, y_val shape: {y_val.shape}')\n",
        "\n",
        "trials = 5\n",
        "\n",
        "history_list = []\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "\n",
        "val_losses = []\n",
        "val_accuracies = []\n",
        "\n",
        "test_losses = []\n",
        "test_accuracies = []\n",
        "\n",
        "\n",
        "for trial in range(trials):\n",
        "    model = build_model(activation='elu',\n",
        "                        kernel_initializer='HeUniform',\n",
        "                        units=2,\n",
        "                        optimizer=tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.7, weight_decay=0.01))\n",
        "    history = train_model(model, X_train, y_train, X_val, y_val, batch_size=32, epochs=500, callbacks=[early_stopping])\n",
        "    history_list.append(history)\n",
        "    results_train = model.evaluate(x=X_train, y=y_train)\n",
        "    results_val = model.evaluate(x=X_val, y=y_val)\n",
        "    results_test = model.evaluate(x=X_test_monk3, y=y_test_monk3)\n",
        "    # train\n",
        "    train_losses.append(results_train[0])\n",
        "    train_accuracies.append(results_train[1])\n",
        "    # val\n",
        "    val_losses.append(results_val[0])\n",
        "    val_accuracies.append(results_val[1])\n",
        "    # test\n",
        "    test_losses.append(results_test[0])\n",
        "    test_accuracies.append(results_test[1])"
      ],
      "metadata": {
        "id": "EptAHcETmVTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('MODEL REGULARIZATION + EARLY STOPPING')\n",
        "print()\n",
        "print('TRAIN ACCURACY')\n",
        "print(f'train max: {np.amax(train_accuracies)}')\n",
        "print(f'train mean: {np.mean(train_accuracies)}')\n",
        "print(f'train median: {np.median(train_accuracies)}')\n",
        "print(f'train variance: {np.var(train_accuracies)}')\n",
        "print()\n",
        "\n",
        "print('VAL ACCURACY')\n",
        "print(f'val max: {np.amax(val_accuracies)}')\n",
        "print(f'val mean: {np.mean(val_accuracies)}')\n",
        "print(f'val median: {np.median(val_accuracies)}')\n",
        "print(f'val variance: {np.var(val_accuracies)}')\n",
        "print()\n",
        "\n",
        "\n",
        "print('TEST ACCURACY')\n",
        "print(f'test max: {np.amax(test_accuracies)}')\n",
        "print(f'test mean: {np.mean(test_accuracies)}')\n",
        "print(f'test median: {np.median(test_accuracies)}')\n",
        "print(f'test variance: {np.var(test_accuracies)}')"
      ],
      "metadata": {
        "id": "6B4DUiSuneGr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Random Forest**"
      ],
      "metadata": {
        "id": "GQy7Pz41_2ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to categorical variables otherwise used by the RF as numerical\n",
        "monk_3_train_new = monk_3_train.astype(str)\n",
        "monk_3_test_new = monk_3_test.astype(str)\n",
        "\n",
        "print(monk_3_train_new.dtypes)\n",
        "print(monk_3_test_new.dtypes)"
      ],
      "metadata": {
        "id": "B_xw3TB-_mKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validation accuracy on the individual folds.\n",
        "accuracy_per_fold = []\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# Run a 10-folds cross-validation.\n",
        "for  fold_idx, (train_indices, val_indices) in enumerate(kfold.split(X_design_monk3, y_design_monk3)):\n",
        "  print(f\"Running fold {fold_idx+1}\")\n",
        "\n",
        "  # Extract the training and testing examples.\n",
        "  train_fold = monk_3_train_new.iloc[train_indices, :].astype(str)\n",
        "  val_fold = monk_3_train_new.iloc[val_indices, :].astype(str)\n",
        "\n",
        "  # Specify the model\n",
        "  model = create_rf_model(num_trees=200,\n",
        "                          max_depth=30,\n",
        "                          min_examples=15,\n",
        "                          num_candidate_attributes=0,\n",
        "                          algorithm= 'RANDOM',\n",
        "                          verbose=0)\n",
        "\n",
        "  model.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "  # Train the model\n",
        "  model.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(train_fold, label='class'))\n",
        "\n",
        "  # Evaluate the model.\n",
        "  accuracy = model.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(val_fold, label='class'), return_dict=True)['accuracy']\n",
        "  print(f'val_accuracy: {accuracy}')\n",
        "  accuracy_per_fold.append(accuracy)\n",
        "\n",
        "print(f\"Mean Accuracy: {mean(accuracy_per_fold)}\")\n",
        "print(f\"Stdev Accuracy: {stdev(accuracy_per_fold)}\")"
      ],
      "metadata": {
        "id": "-C0VeBq-n898"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "rf3 = create_rf_model(num_trees=200,\n",
        "                      max_depth=30,\n",
        "                      min_examples=15,\n",
        "                      algorithm='RANDOM',\n",
        "                      num_candidate_attributes=0)\n",
        "\n",
        "# Model assessment on training/test set\n",
        "rf3.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "# Train the model\n",
        "rf3.fit(x=tfdf.keras.pd_dataframe_to_tf_dataset(monk_3_train_new, label='class'))"
      ],
      "metadata": {
        "id": "2_IqBH5nAi_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary of the model\n",
        "rf3.summary()"
      ],
      "metadata": {
        "id": "9_w-hbR9AnGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loss/accuracy\n",
        "print('TRAINING:\\n')\n",
        "evaluation_TR = rf3.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_3_train_new, label='class'), return_dict=True)\n",
        "\n",
        "for name, value in evaluation_TR.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "RBwIpr1NAm7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test loss/accuracy\n",
        "print('TEST:\\n')\n",
        "evaluation_TS = rf3.evaluate(tfdf.keras.pd_dataframe_to_tf_dataset(monk_3_test_new, label='class'), return_dict=True)\n",
        "\n",
        "for name, value in evaluation_TS.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ],
      "metadata": {
        "id": "VoC1mH8wAi8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Support Vector Machine - SVM**"
      ],
      "metadata": {
        "id": "J4ysXAq0_3N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Stratified K-Fold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# Specify the model\n",
        "model = create_svm_model(kernel='rbf',\n",
        "                          C=1,\n",
        "                          gamma='scale')\n",
        "\n",
        "val_scores = cross_val_score(model, X_design_monk3, y_design_monk3, cv=kfold, scoring=make_scorer(accuracy_score))\n",
        "print(val_scores)\n",
        "print(f'val_mean: {mean(val_scores)}')\n",
        "print(f'val_stdev: {stdev(val_scores)}')"
      ],
      "metadata": {
        "id": "7AW7WE0qoiY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "svm3 = create_svm_model(kernel='rbf',\n",
        "                          C=1,\n",
        "                          gamma='scale')\n",
        "\n",
        "# Train the model\n",
        "svm3.fit(X_design_monk3, y_design_monk3)"
      ],
      "metadata": {
        "id": "MxclWDPT_mHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model assessment on training/test set\n",
        "y_pred_TR = svm3.predict(X_design_monk3)\n",
        "Accuracy_TR = accuracy_score(y_design_monk3, y_pred_TR)\n",
        "\n",
        "y_pred_TS = svm3.predict(X_test_monk3)\n",
        "Accuracy_TS = accuracy_score(y_test_monk3, y_pred_TS)\n",
        "\n",
        "print(f'Train Accuracy: {Accuracy_TR}')\n",
        "print(f'Test Accuracy: {Accuracy_TS}')"
      ],
      "metadata": {
        "id": "XSpCh27TA0et"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}